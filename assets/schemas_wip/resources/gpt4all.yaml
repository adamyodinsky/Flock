# yaml-language-server: $schema=../../json_schemas/main/LLMSchema.json
---
apiVersion: flock/v1
kind: LLM
namespace: default
metadata:
  name: my-gpt4all-llm
  description: openai language model
  labels:
    app: my_app
spec:
  vendor: GPT4All
  options:
    model: /Users/adamyodinsky/.flock/models/ggml-gpt4all-l13b-snoozy.bin
    temp: 0.28
    top_p: 0.95
    top_k: 40
    n_batch: 9
    repeat_penalty: 1.1

    # n_ctx: int = Field(512, alias="n_ctx")
    # n_parts: int = Field(-1, alias="n_parts")
    # seed: int = Field(0, alias="seed")
    # f16_kv: bool = Field(False, alias="f16_kv")
    # logits_all: bool = Field(False, alias="logits_all")
    # vocab_only: bool = Field(False, alias="vocab_only")
    # use_mlock: bool = Field(False, alias="use_mlock")
    # embedding: bool = Field(False, alias="embedding")
    # n_threads: Optional[int] = Field(4, alias="n_threads")
    # n_predict: Optional[int] = 256
    # echo: Optional[bool] = False
    # stop: Optional[List[str]] = []
    # repeat_last_n: Optional[int] = 64
    # streaming: bool = False
